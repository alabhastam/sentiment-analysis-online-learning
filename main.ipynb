{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743c44da",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-20T19:56:51.199354Z",
     "iopub.status.busy": "2025-09-20T19:56:51.198995Z",
     "iopub.status.idle": "2025-09-20T19:56:53.162971Z",
     "shell.execute_reply": "2025-09-20T19:56:53.161927Z"
    },
    "papermill": {
     "duration": 1.969973,
     "end_time": "2025-09-20T19:56:53.164754",
     "exception": false,
     "start_time": "2025-09-20T19:56:51.194781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776b19f",
   "metadata": {
    "papermill": {
     "duration": 0.002082,
     "end_time": "2025-09-20T19:56:53.169773",
     "exception": false,
     "start_time": "2025-09-20T19:56:53.167691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color:#1e1e1e; color:#d4d4d4; padding:25px; border-radius:10px; font-family:Segoe UI, sans-serif; line-height:1.6;\">\n",
    "\n",
    "<h1 style=\"color:#61dafb; text-align:center;\">üì° Real-Time Sentiment Analysis with Online Learning</h1>\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">1Ô∏è‚É£ Motivation</h2>\n",
    "<p>\n",
    "In the age of social media, data arrives continuously ‚Äî tweets, comments, and posts are generated every second. \n",
    "Traditional <b>batch learning</b> models require retraining from scratch when new data arrives, which:\n",
    "</p>\n",
    "<ul>\n",
    "<li>Consumes significant resources (CPU, memory, time).</li>\n",
    "<li>Cannot adapt fast enough to sudden changes in trends or topics.</li>\n",
    "<li>Is impractical for endless data streams.</li>\n",
    "</ul>\n",
    "<p>\n",
    "<b>Online Learning</b> (or Incremental Learning) solves this by updating the model immediately as new data arrives, without reprocessing all past data. \n",
    "This makes it ideal for <span style=\"color:#98c379;\">real-time sentiment analysis</span>, fraud detection, and dynamic recommendation systems.\n",
    "</p>\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">2Ô∏è‚É£ Project Goal</h2>\n",
    "<p>\n",
    "We will build an <b>online sentiment analysis system</b> that processes tweets in small batches, \n",
    "predicts their sentiment (<span style=\"color:#98c379;\">Positive</span> / <span style=\"color:#e06c75;\">Negative</span>), \n",
    "and continuously improves as new data arrives.\n",
    "</p>\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">3Ô∏è‚É£ Dataset ‚Äî Sentiment140</h2>\n",
    "<ul>\n",
    "<li><b>Source:</b> <a href=\"https://www.kaggle.com/datasets/kazanova/sentiment140\" style=\"color:#61dafb;\">Sentiment140 Dataset</a></li>\n",
    "<li><b>Size:</b> 1.6 million labeled tweets</li>\n",
    "<li><b>Labels:</b> 0 = Negative, 4 = Positive (will convert 4 ‚Üí 1 for binary classification)</li>\n",
    "<li><b>Content:</b> Raw tweet text, no emojis, collected via Twitter API</li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">4Ô∏è‚É£ Approach</h2>\n",
    "<ol>\n",
    "<li><b>Load and preprocess</b> the Sentiment140 dataset.</li>\n",
    "<li>Use <code>HashingVectorizer</code> for text-to-vector transformation (efficient in streaming scenarios).</li>\n",
    "<li>Train an <b>SGDClassifier</b> model incrementally using <code>partial_fit</code>.</li>\n",
    "<li>Simulate a stream of tweets in <b>mini-batches</b> (batch size: 10,000 rows).</li>\n",
    "<li>Record and plot <b>accuracy over time</b> to see model improvement.</li>\n",
    "</ol>\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">5Ô∏è‚É£ Why Online Learning for This Task?</h2>\n",
    "<ul>\n",
    "<li>Handles <b>continuous inflow</b> of social media data.</li>\n",
    "<li>Works within <b>limited memory</b> ‚Äî no need to store all past tweets.</li>\n",
    "<li><b>Fast adaptation</b> to changing topics, slang, and trends.</li>\n",
    "</ul>\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">6Ô∏è‚É£ Expected Outcome</h2>\n",
    "<p>\n",
    "By the end of this notebook, we‚Äôll have a working real-time sentiment classifier that can learn from new tweets without full retraining. \n",
    "This approach can be extended to live Twitter APIs and other streaming data sources.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border: 1px solid #333; margin: 20px 0;\">\n",
    "<p style=\"text-align:center; color:#888;\">\n",
    "<strong>Author's Note:</strong> This notebook uses a simulated streaming setup on the Sentiment140 dataset. The same code can be adapted to handle live Twitter data.\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f45a8",
   "metadata": {
    "papermill": {
     "duration": 0.001911,
     "end_time": "2025-09-20T19:56:53.173933",
     "exception": false,
     "start_time": "2025-09-20T19:56:53.172022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color:#1e1e1e; color:#d4d4d4; padding:20px; border-radius:8px; font-family:Segoe UI;\">\n",
    "<h2 style=\"color:#56b6c2;\">Step 1 ‚Äî Import Libraries & Load Dataset</h2>\n",
    "<p>We start by importing the core Python libraries for online learning and sentiment analysis:</p>\n",
    "<ul>\n",
    "<li><b>pandas</b> ‚Äî to handle tabular data</li>\n",
    "<li><b>numpy</b> ‚Äî for numeric operations</li>\n",
    "<li><b>sklearn</b> ‚Äî for vectorization and the online learning model</li>\n",
    "<li><b>matplotlib</b> ‚Äî for accuracy visualization</li>\n",
    "</ul>\n",
    "<p>We then load a labeled Twitter dataset, where each sample contains the text of the tweet and a label:\n",
    "<span style=\"color:#98c379;\">1 for positive</span> and <span style=\"color:#e06c75;\">0 for negative</span>.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446c7dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T19:56:53.179779Z",
     "iopub.status.busy": "2025-09-20T19:56:53.179327Z",
     "iopub.status.idle": "2025-09-20T19:56:55.059518Z",
     "shell.execute_reply": "2025-09-20T19:56:55.058477Z"
    },
    "papermill": {
     "duration": 1.885111,
     "end_time": "2025-09-20T19:56:55.061205",
     "exception": false,
     "start_time": "2025-09-20T19:56:53.176094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19ed1b",
   "metadata": {
    "papermill": {
     "duration": 0.001887,
     "end_time": "2025-09-20T19:56:55.065521",
     "exception": false,
     "start_time": "2025-09-20T19:56:55.063634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color:#1e1e1e; color:#d4d4d4; padding:25px; border-radius:10px; font-family:Segoe UI, sans-serif; line-height:1.6;\">\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">Step 2 ‚Äî Load & Preprocess the Dataset</h2>\n",
    "\n",
    "<p>\n",
    "In this step, we load the <b>Sentiment140 dataset</b> and prepare it for streaming-based online learning. \n",
    "Since the dataset includes extra columns we don‚Äôt need, we will:\n",
    "</p>\n",
    "\n",
    "<ol>\n",
    "<li>Read the CSV with <code>pandas</code> using the correct encoding (<code>latin-1</code>) to handle special characters.</li>\n",
    "<li>Keep only the <b>label</b> and <b>tweet text</b> columns.</li>\n",
    "<li>Convert labels:\n",
    "    <span style=\"color:#e06c75;\">0</span> ‚Üí Negative,\n",
    "    <span style=\"color:#98c379;\">4</span> ‚Üí Positive ‚Üí mapped to <span style=\"color:#98c379;\">1</span> for binary classification.</li>\n",
    "<li>Shuffle the dataset to simulate random arrival of tweets in a data stream.</li>\n",
    "<li>Split into training and test datasets, where the test set remains fixed for evaluation across streaming batches.</li>\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "This preprocessing ensures our model sees tweets in a mixed, unpredictable order ‚Äî closer to a real online environment.\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386766b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T19:56:55.071332Z",
     "iopub.status.busy": "2025-09-20T19:56:55.070860Z",
     "iopub.status.idle": "2025-09-20T19:57:02.500288Z",
     "shell.execute_reply": "2025-09-20T19:57:02.499028Z"
    },
    "papermill": {
     "duration": 7.434202,
     "end_time": "2025-09-20T19:57:02.501922",
     "exception": false,
     "start_time": "2025-09-20T19:56:55.067720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0             @chrishasboobs AHHH I HOPE YOUR OK!!! \n",
      "1      0  @misstoriblack cool , i have no tweet apps  fo...\n",
      "2      0  @TiannaChaos i know  just family drama. its la...\n",
      "3      0  School email won't open  and I have geography ...\n",
      "4      0                             upper airways problem \n",
      "label\n",
      "1    720035\n",
      "0    719965\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load Sentiment140 dataset\n",
    "# Kaggle path: /kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\n",
    "# Columns: target, ids, date, flag, user, text\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\",\n",
    "    encoding=\"latin-1\",\n",
    "    header=None\n",
    ")\n",
    "\n",
    "# Keep only sentiment and text\n",
    "df = df[[0, 5]]\n",
    "df.columns = ['label', 'text']\n",
    "\n",
    "# Map labels: 0 -> 0 (negative), 4 -> 1 (positive)\n",
    "df['label'] = df['label'].replace({4: 1})\n",
    "\n",
    "# Shuffle dataset to simulate random streaming\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Train-test split (e.g., 90% train for streaming simulation, 10% fixed test set)\n",
    "train_size = int(len(df) * 0.9)\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "# Show dataset info\n",
    "print(train_df.head())\n",
    "print(train_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a52eed",
   "metadata": {
    "papermill": {
     "duration": 0.001981,
     "end_time": "2025-09-20T19:57:02.506376",
     "exception": false,
     "start_time": "2025-09-20T19:57:02.504395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background-color:#1e1e1e; color:#d4d4d4; padding:25px; border-radius:10px; font-family:Segoe UI, sans-serif; line-height:1.6;\">\n",
    "\n",
    "<h2 style=\"color:#56b6c2;\">Step 2 Output ‚Äî Preprocessed Dataset Overview</h2>\n",
    "\n",
    "<p>\n",
    "After loading and preprocessing the Sentiment140 dataset, we now have a clean,  \n",
    "stream-ready dataframe containing only two columns:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "<li><span style=\"color:#61dafb;\">label</span> ‚Äî Sentiment label (0 = Negative, 1 = Positive).</li>\n",
    "<li><span style=\"color:#61dafb;\">text</span> ‚Äî The raw tweet content.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "<h3 style=\"color:#98c379;\">Class Distribution</h3>\n",
    "<pre style=\"background-color:#2d2d2d; padding:10px; border-radius:5px;\">\n",
    "1 (Positive)    720,035\n",
    "0 (Negative)    719,965\n",
    "</pre>\n",
    "\n",
    "<p>\n",
    "üí° The dataset is nicely balanced, with nearly equal numbers of positive and negative tweets.  \n",
    "This helps ensure fair training and evaluation in our streaming simulation.\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2477,
     "sourceId": 4140,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.888567,
   "end_time": "2025-09-20T19:57:03.329770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-20T19:56:45.441203",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
